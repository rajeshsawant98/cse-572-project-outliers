# %%
# %%
# 1Ô∏è‚É£ Ensure required packages
import importlib, sys
def ensure(pkg):
    try:
        importlib.import_module(pkg)
        print(f"{pkg} available")
    except ImportError:
        print(f"{pkg} missing ‚Äî installing via pip.")
        !{sys.executable} -m pip install {pkg}

for p in ['pandas','numpy','matplotlib','seaborn','xgboost','scikit-learn','joblib']:
    ensure(p)


# %%
# %%
# 2Ô∏è‚É£ Load dataset
import pandas as pd
df = pd.read_csv("train.csv")
print("Columns in dataset:")
print(df.columns.tolist())
print("Shape:", df.shape)
df.head()


# %%
# %%
# 3Ô∏è‚É£ Basic data exploration
print("\nData info:")
df.info()

print("\nMissing values per column:")
display(df.isnull().sum())

print("\nDuplicate rows:", df.duplicated().sum())

# Summary statistics
print("\nNumerical summary statistics:")
display(df.describe())

# Count unique values for categorical columns
cat_cols = df.select_dtypes(include=['object', 'category']).columns
for col in cat_cols:
    print(f"\nUnique value counts for {col}:")
    display(df[col].value_counts())


# %%
# %%
# 4Ô∏è‚É£ Handle missing values
num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
cat_cols = df.select_dtypes(include=['object']).columns.tolist()

df[num_cols] = df[num_cols].fillna(df[num_cols].median())
df[cat_cols] = df[cat_cols].fillna(df[cat_cols].mode().iloc[0])


# %%
# %%
# 5Ô∏è‚É£ Set target columns
num_target_cols = ['Premium Amount']       # numeric target
cat_target_cols = ['Policy Type']          # categorical target

feature_cols = [c for c in df.columns if c not in num_target_cols + cat_target_cols + ['id','Policy Start Date']]

X = df[feature_cols]
y_num = df[num_target_cols]
y_cat = df[cat_target_cols]

print("Feature columns:", X.columns.tolist())
print("Numeric targets:", num_target_cols)
print("Categorical targets:", cat_target_cols)


# %%
# %%
# 6Ô∏è‚É£ Encode categorical features and targets
X_encoded = pd.get_dummies(X, drop_first=True)

from sklearn.preprocessing import LabelEncoder
cat_target_encoders = {}
for col in y_cat.columns:
    le = LabelEncoder()
    y_cat[col] = le.fit_transform(y_cat[col])
    cat_target_encoders[col] = le


# %%
# %%
# 7Ô∏è‚É£ Train-test split
from sklearn.model_selection import train_test_split

# Combine numeric + categorical targets
y_all = pd.concat([y_num, y_cat], axis=1)

X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_all, test_size=0.2, random_state=42)

y_num_train = y_train[y_num.columns]
y_num_test = y_test[y_num.columns]
y_cat_train = y_train[y_cat.columns]
y_cat_test = y_test[y_cat.columns]


# %%
# %%
# 8Ô∏è‚É£ Train XGBoost models
from xgboost import XGBRegressor, XGBClassifier
from sklearn.multioutput import MultiOutputRegressor, MultiOutputClassifier

# Numeric targets
xgb_reg = MultiOutputRegressor(
    XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)
)
xgb_reg.fit(X_train, y_num_train)
print("Numeric targets model trained.")

# Categorical targets
xgb_clf = MultiOutputClassifier(
    XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', n_estimators=100, random_state=42)
)
xgb_clf.fit(X_train, y_cat_train)
print("Categorical targets model trained.")


# %%
# %%
# 9Ô∏è‚É£ Predictions & evaluation
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score
import numpy as np

# Numeric predictions
y_num_pred = xgb_reg.predict(X_test)
y_num_pred = np.atleast_2d(y_num_pred)
print("\nNumeric Predictions (first 5 rows):")
print(y_num_pred[:5])

print("\nNumeric Targets Evaluation:")
for i, col in enumerate(y_num_test.columns):
    pred_col = y_num_pred[:, i] if y_num_pred.shape[1] > 1 else y_num_pred.ravel()
    mse_col = mean_squared_error(y_num_test[col], pred_col)
    r2_col = r2_score(y_num_test[col], pred_col)
    print(f"{col}: MSE={mse_col:.4f}, R2={r2_col:.4f}")

# Categorical predictions
y_cat_pred = xgb_clf.predict(X_test)
y_cat_pred = np.atleast_2d(y_cat_pred)
print("\nCategorical Predictions (first 5 rows):")
print(y_cat_pred[:5])

print("\nCategorical Targets Evaluation:")
for i, col in enumerate(y_cat_test.columns):
    pred_col = y_cat_pred[:, i] if y_cat_pred.shape[1] > 1 else y_cat_pred.ravel()
    acc_col = accuracy_score(y_cat_test[col], pred_col)
    print(f"{col}: Accuracy={acc_col:.4f}")


# %%
# %%
# 10Ô∏è‚É£ Save models
import joblib

joblib.dump(xgb_reg, "xgb_numeric_model.pkl")
joblib.dump(xgb_clf, "xgb_categorical_model.pkl")
print("Models saved.")


# %%
# %%
# üîü Mean Average Precision (MAP) for categorical predictions
from sklearn.metrics import average_precision_score

# Ensure predictions are in one-hot / binary format if multi-label
if y_cat_pred.shape[1] == 1:
    # Single-label, convert to binary for average_precision_score
    y_true_bin = pd.get_dummies(y_cat_test)
    y_pred_bin = pd.get_dummies(pd.DataFrame(y_cat_pred, columns=y_cat_test.columns))
else:
    y_true_bin = y_cat_test
    y_pred_bin = pd.DataFrame(y_cat_pred, columns=y_cat_test.columns)

map_score = average_precision_score(y_true_bin, y_pred_bin)
print(f"\nMean Average Precision (MAP) for categorical predictions: {map_score:.4f}")



